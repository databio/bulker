{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to biobase\n",
    "\n",
    "Bulker comes with a core manifest called `biobase` that includes more than 50 common bioinformatics tools. Biobase is useful for everyday interactive analysis, basic pipelines, and also as a starting point for more complicated manifests. In this tutorial we'll show how to activate biobase and use it for some interactive RNA-seq analysis, and to run a pipeline. I assume you've already gone through the [install and configure](install.md) instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Loading the biobase crate\n",
    "\n",
    "Let's load the biobase crate, which is available on the bulker registry. First I'm initializing an empty bulker config for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guessing container engine is docker.\n",
      "Wrote new configuration file: biobase_example/bulker_config.yaml\n"
     ]
    }
   ],
   "source": [
    "export BULKERCFG=\"biobase_example/bulker_config.yaml\"\n",
    "rm $BULKERCFG\n",
    "bulker init -c $BULKERCFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulker config: /home/nsheff/code/bulker/docs_jupyter/biobase_example/bulker_config.yaml\n",
      "Importing crate 'bulker/alpine:default' from '/home/nsheff/bulker_crates/bulker/alpine/default'.\n",
      "Importing crate 'bulker/coreutils:default' from '/home/nsheff/bulker_crates/bulker/coreutils/default'.\n",
      "Loading manifest: 'bulker/biobase:default'. Activate with 'bulker activate bulker/biobase:default'.\n",
      "Commands available: aws, ascp, bamtools, bedClip, bedCommonRegions, bedGraphToBigWig, bedIntersect, bedItemOverlapCount, bedops, bedPileUps, bedToBigBed, bedtools, bigWigAverageOverBed, bigWigCat, bigWigSummary, bismark, bissnp, blast, bowtie2, bowtie, bsmap, bwa, cellranger, cufflinks, curl, cutadapt, faSplit, fastq-dump, fasterq-dump, vdb-config, fastqc, gatk, gt, hisat2, homer, kallisto, khmer, liftOver, macs2, mashmap, picard, pigz, prefetch, R, repeatmasker, rg, Rscript, sambamba, salmon, samtools, segway, seqkit, seqtk, skewer, samblaster, STAR, tabix, trim_galore, trimmomatic, vep, wigToBigWig\n"
     ]
    }
   ],
   "source": [
    "bulker load biobase -f $HOME/code/hub.bulker.io/bulker/biobase.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see this crate offers many common bioinformatics tools, like `samtools` and `bowtie2`. You can see this crate in your list of available crates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available crates:\n",
      "bulker/biobase:default -- /home/nsheff/bulker_crates/bulker/biobase/default\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "bulker list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before activating the crate, these commands are not available because they are not installed natively on this sytem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Command 'samtools' not found, but can be installed with:\n",
      "\n",
      "sudo apt install samtools\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "127",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "samtools --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Command 'kallisto' not found, but can be installed with:\n",
      "\n",
      "sudo apt install kallisto\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "127",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "kallisto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we activate the crate. In a shell you just type:\n",
    "\n",
    "```\n",
    "bulker activate biobase\n",
    "```\n",
    "\n",
    "Due to a limitation with jupyter, because bulker spawns a new shell by default, you have to things a bit differently...there 2 ways to use bulker with a jupyter note book:\n",
    "\n",
    "1. You can simply activate the crate before starting the notebook (the easier way).\n",
    "2. You can use this `eval` trick below to activate the crate in the existing jupyter shell.\n",
    "\n",
    "Either way should have the same affect as typing `bulker activate biobase` outside of jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulker config: /home/nsheff/pCloudSync/env/bulker_config/zither.yaml\n",
      "Activating bulker crate: biobase\n"
     ]
    }
   ],
   "source": [
    "eval \"$(bulker activate -e -p biobase)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth emphasizing: **that single line of code is all you need to do to \"install\" dozens of common bioinformatics tools**. Now, in just a few minutes you've given yourself the ability to create a portable computing environment instantly, on demand. \n",
    "\n",
    "Now we can inspect what commands are made available by this crate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulker config: /home/nsheff/code/bulker/docs_jupyter/biobase_example/bulker_config.yaml\n",
      "Bulker manifest: bulker/biobase\n",
      "Crate path: /home/nsheff/bulker_crates/bulker/biobase/default\n",
      "Available commands: ['cellranger', 'fasterq-dump', 'cksum', 'hisat2', 'paste', 'chmod', 'aws', 'picard', 'arch', 'tail', 'unexpand', 'liftOver', 'cutadapt', 'expr', 'rm', 'STAR', 'base32', 'runcon', 'timeout', 'gt', 'samtools', 'nohup', 'rmdir', 'kallisto', 'sleep', 'vdir', 'bowtie2', 'pigz', 'samblaster', 'echo', 'base64', 'bwa', 'which', 'bash', 'shuf', 'homer', 'trimmomatic', 'salmon', 'stty', 'fastqc', 'cp', 'chgrp', 'ptx', 'blast', 'mkfifo', 'mashmap', 'seq', 'du', 'bigWigCat', 'logname', 'factor', 'vep', 'dircolors', 'bedCommonRegions', 'pwd', 'bigWigAverageOverBed', 'expand', 'sh', 'mkdir', 'whoami', 'bedops', 'R', 'bedPileUps', 'tsort', 'users', 'prefetch', 'fmt', 'truncate', 'csplit', 'repeatmasker', 'bissnp', 'gatk', 'uptime', 'tee', 'touch', 'false', 'od', 'mv', 'numfmt', 'bismark', 'seqtk', 'fastq-dump', 'b2sum', 'bamtools', 'groups', 'id', 'docker', 'seqkit', 'basename', 'cat', 'cufflinks', 'bedtools', 'nproc', 'unlink', 'md5sum', 'link', 'cut', 'sambamba', 'bowtie', 'pr', 'shred', 'bedItemOverlapCount', 'bsmap', 'bedGraphToBigWig', 'yes', 'lesspipe', 'dir', 'sha512sum', 'skewer', 'tr', 'split', 'hostname', 'macs2', 'Rscript', 'sha256sum', 'chown', 'tty', 'uname', 'pinky', 'ascp', 'vdb-config', 'grep', 'true', 'bedClip', 'wc', 'faSplit', 'printf', 'tabix', 'install', 'bigWigSummary', 'stdbuf', 'ln', 'bedIntersect', 'khmer', 'trim_galore', 'mknod', 'df', 'comm', 'sha224sum', 'realpath', 'dd', 'pathchk', 'uniq', 'nl', 'test', 'curl', 'ls', 'env', 'sha384sum', 'tac', 'segway', 'fold', 'bedToBigBed', 'who', 'wigToBigWig', 'hostid', 'printenv', 'sha1sum', 'join', 'nice', 'stat', 'date', 'awk', 'sed', 'sum', 'sync', 'rg', 'dirname', 'head', 'sort']\n"
     ]
    }
   ],
   "source": [
    "bulker inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any of these commands can be run as if they are native, but they will actually be running in containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samtools 1.10\n",
      "Using htslib 1.10.2\n",
      "Copyright (C) 2019 Genome Research Ltd.\n"
     ]
    }
   ],
   "source": [
    "samtools --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kallisto 0.46.2\n",
      "\n",
      "Usage: kallisto <CMD> [arguments] ..\n",
      "\n",
      "Where <CMD> can be one of:\n",
      "\n",
      "    index         Builds a kallisto index \n",
      "    quant         Runs the quantification algorithm \n",
      "    bus           Generate BUS files for single-cell data \n",
      "    pseudo        Runs the pseudoalignment step \n",
      "    merge         Merges several batch runs \n",
      "    h5dump        Converts HDF5-formatted results to plaintext\n",
      "    inspect       Inspects and gives information about an index\n",
      "    version       Prints version information\n",
      "    cite          Prints citation information\n",
      "\n",
      "Running kallisto <CMD> without arguments prints usage information for <CMD>\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "kallisto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutadapt --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running an analysis\n",
    "\n",
    "Now that we've proven we can run each of these commands, let's put them all together and run a whole pipeline. Since the environment we've just activated has all those commands available as if they were installed natively, all we have to do is run a bunch of commands in succession and they will automatically run in individual containers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab some reads from SRA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-10 14:36:20--  https://sra-download.ncbi.nlm.nih.gov/traces/sra10/SRR/011497/SRR11773889\n",
      "Resolving sra-download.ncbi.nlm.nih.gov (sra-download.ncbi.nlm.nih.gov)... 130.14.250.25, 130.14.250.24, 165.112.9.231\n",
      "Connecting to sra-download.ncbi.nlm.nih.gov (sra-download.ncbi.nlm.nih.gov)|130.14.250.25|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15095418 (14M) [application/octet-stream]\n",
      "Saving to: ‘SRR11773889’\n",
      "\n",
      "SRR11773889         100%[===================>]  14.40M  49.3KB/s    in 2m 31s  \n",
      "\n",
      "2020-07-10 14:38:53 (97.4 KB/s) - ‘SRR11773889’ saved [15095418/15095418]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wget  https://sra-download.ncbi.nlm.nih.gov/traces/sra10/SRR/011497/SRR11773889"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spots read      : 742,462\n",
      "reads read      : 742,462\n",
      "reads written   : 742,462\n"
     ]
    }
   ],
   "source": [
    "fasterq-dump -L info SRR11773889 -O raw_reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to try to align these. We'll use refgenie to easily pull some bowtie2 indexes. Refgenie is included in the biobase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: refgenie in /home/nsheff/.local/lib/python3.5/site-packages (0.7.0.dev0)\n",
      "Requirement already satisfied: ubiquerg>=0.4.8 in /home/nsheff/.local/lib/python3.5/site-packages (from refgenie) (0.4.10.dev0)\n",
      "Requirement already satisfied: yacman>=0.6.1 in /home/nsheff/.local/lib/python3.5/site-packages (from refgenie) (0.6.2)\n",
      "Requirement already satisfied: piper>=0.12.1 in /home/nsheff/.local/lib/python3.5/site-packages (from refgenie) (0.12.1)\n",
      "Requirement already satisfied: logmuse>=0.2 in /home/nsheff/.local/lib/python3.5/site-packages (from refgenie) (0.2.4)\n",
      "Requirement already satisfied: refgenconf>=0.4.0 in /home/nsheff/.local/lib/python3.5/site-packages (from refgenie) (0.5.0.dev0)\n",
      "Requirement already satisfied: attmap>=0.12.5 in /home/nsheff/.local/lib/python3.5/site-packages (from refgenie) (0.12.9)\n",
      "Requirement already satisfied: oyaml in /home/nsheff/.local/lib/python3.5/site-packages (from yacman>=0.6.1->refgenie) (0.9)\n",
      "Requirement already satisfied: pyyaml>=3.13 in /home/nsheff/.local/lib/python3.5/site-packages (from yacman>=0.6.1->refgenie) (5.1)\n",
      "Requirement already satisfied: pandas in /home/nsheff/.local/lib/python3.5/site-packages (from piper>=0.12.1->refgenie) (0.24.2)\n",
      "Requirement already satisfied: psutil in /home/nsheff/.local/lib/python3.5/site-packages (from piper>=0.12.1->refgenie) (5.6.1)\n",
      "Requirement already satisfied: future in /home/nsheff/.local/lib/python3.5/site-packages (from refgenconf>=0.4.0->refgenie) (0.17.1)\n",
      "Requirement already satisfied: requests in /home/nsheff/.local/lib/python3.5/site-packages (from refgenconf>=0.4.0->refgenie) (2.21.0)\n",
      "Requirement already satisfied: tqdm in /home/nsheff/.local/lib/python3.5/site-packages (from refgenconf>=0.4.0->refgenie) (4.32.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/nsheff/.local/lib/python3.5/site-packages (from pandas->piper>=0.12.1->refgenie) (1.16.2)\n",
      "Requirement already satisfied: pytz>=2011k in /home/nsheff/.local/lib/python3.5/site-packages (from pandas->piper>=0.12.1->refgenie) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/nsheff/.local/lib/python3.5/site-packages (from pandas->piper>=0.12.1->refgenie) (2.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nsheff/.local/lib/python3.5/site-packages (from requests->refgenconf>=0.4.0->refgenie) (2019.3.9)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/nsheff/.local/lib/python3.5/site-packages (from requests->refgenconf>=0.4.0->refgenie) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/nsheff/.local/lib/python3.5/site-packages (from requests->refgenconf>=0.4.0->refgenie) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/nsheff/.local/lib/python3.5/site-packages (from requests->refgenconf>=0.4.0->refgenie) (2.8)\n",
      "Requirement already satisfied: six>=1.5 in /home/nsheff/.local/lib/python3.5/site-packages (from python-dateutil>=2.5.0->pandas->piper>=0.12.1->refgenie) (1.12.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Initializing refgenie genome configuration\n",
      "Wrote new refgenie genome configuration file: peppro_example/refgenie.yaml\n",
      "'hs38d1/fasta:default' archive size: 1.7MB\n",
      "Downloading URL: http://staging.refgenomes.databio.org/v2/asset/hs38d1/fasta/archive\n",
      "hs38d1/fasta:default: 1.74MB [00:00, 28.8MB/s]\n",
      "Download complete: /home/nsheff/code/bulker/docs_jupyter/peppro_example/hs38d1/fasta__default.tgz\n",
      "Extracting asset tarball and saving to: /home/nsheff/code/bulker/docs_jupyter/peppro_example/hs38d1/fasta/default\n",
      "Default tag for 'hs38d1/fasta' set to: default\n",
      "'hs38d1/bowtie2_index:default' archive size: 8.8MB\n",
      "Downloading URL: http://staging.refgenomes.databio.org/v2/asset/hs38d1/bowtie2_index/archive\n",
      "hs38d1/bowtie2_index:default: 9.22MB [00:00, 21.1MB/s]                          \n",
      "Download complete: /home/nsheff/code/bulker/docs_jupyter/peppro_example/hs38d1/bowtie2_index__default.tgz\n",
      "Extracting asset tarball and saving to: /home/nsheff/code/bulker/docs_jupyter/peppro_example/hs38d1/bowtie2_index/default\n",
      "Default tag for 'hs38d1/bowtie2_index' set to: default\n"
     ]
    }
   ],
   "source": [
    "export REFGENIE=\"biobase_example/refgenie.yaml\"\n",
    "refgenie init -c $REFGENIE -s http://staging.refgenomes.databio.org\n",
    "refgenie pull t7/bowtie2_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742462 reads; of these:\n",
      "  742462 (100.00%) were unpaired; of these:\n",
      "    742461 (100.00%) aligned 0 times\n",
      "    0 (0.00%) aligned exactly 1 time\n",
      "    1 (0.00%) aligned >1 times\n",
      "0.00% overall alignment rate\n"
     ]
    }
   ],
   "source": [
    "bowtie2 -x `refgenie seek rCRSd/bowtie2_index` raw_reads/SRR11773889.fastq -S aligned.sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742462 reads; of these:\n",
      "  742462 (100.00%) were unpaired; of these:\n",
      "    49655 (6.69%) aligned 0 times\n",
      "    689848 (92.91%) aligned exactly 1 time\n",
      "    2959 (0.40%) aligned >1 times\n",
      "93.31% overall alignment rate\n"
     ]
    }
   ],
   "source": [
    "bowtie2 -x `refgenie seek t7/bowtie2_index` raw_reads/SRR11773889.fastq -S aligned.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline also requires reference genome assets that are managed by [refgenie](http://refgenie.databio.org). If you don't already have an initialized refgenie config, you can easily initialize one like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now execute the example code to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Pipeline run code and environment:\n",
      "\n",
      "*              Command:  `./peppro_example/peppro/pipelines/peppro.py --sample-name test --genome hs38d1 --input peppro_example/peppro/examples/data/test_r1.fq.gz --single-or-paired single -O peppro_example/output/`\n",
      "*         Compute host:  puma\n",
      "*          Working dir:  /home/nsheff/code/bulker/docs_jupyter\n",
      "*            Outfolder:  /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/\n",
      "*  Pipeline started at:   (10-21 11:29:03) elapsed: 0.0 _TIME_\n",
      "\n",
      "### Version log:\n",
      "\n",
      "*       Python version:  2.7.12\n",
      "*          Pypiper dir:  `/home/nsheff/.local/lib/python2.7/site-packages/pypiper`\n",
      "*      Pypiper version:  0.12.0\n",
      "*         Pipeline dir:  `/home/nsheff/code/bulker/docs_jupyter/peppro_example/peppro/pipelines`\n",
      "*     Pipeline version:  0.8.1\n",
      "*        Pipeline hash:  05095a2cc78a2e210916f215dd0828940b894a6f\n",
      "*      Pipeline branch:  * dev\n",
      "*        Pipeline date:  2019-10-21 11:21:23 -0400\n",
      "\n",
      "### Arguments passed to pipeline:\n",
      "\n",
      "*           `TSS_name`:  `None`\n",
      "*            `adapter`:  `fastp`\n",
      "*          `anno_name`:  `None`\n",
      "*         `complexity`:  `True`\n",
      "*        `config_file`:  `peppro.yaml`\n",
      "*              `cores`:  `1`\n",
      "*           `coverage`:  `False`\n",
      "*              `dedup`:  `seqkit`\n",
      "*              `dirty`:  `False`\n",
      "*  `ensembl_gene_body`:  `None`\n",
      "*        `ensembl_tss`:  `None`\n",
      "*          `exon_name`:  `None`\n",
      "*       `force_follow`:  `False`\n",
      "*    `genome_assembly`:  `hs38d1`\n",
      "*              `input`:  `['peppro_example/peppro/examples/data/test_r1.fq.gz']`\n",
      "*             `input2`:  `None`\n",
      "*        `intron_name`:  `None`\n",
      "*               `keep`:  `False`\n",
      "*             `logdev`:  `False`\n",
      "*            `max_len`:  `30`\n",
      "*                `mem`:  `4000`\n",
      "*          `new_start`:  `False`\n",
      "*            `no_fifo`:  `False`\n",
      "*      `output_parent`:  `peppro_example/output/`\n",
      "*         `paired_end`:  `False`\n",
      "*              `parts`:  `4`\n",
      "*           `pre_name`:  `None`\n",
      "*      `prealignments`:  `[]`\n",
      "*           `protocol`:  `pro`\n",
      "*            `recover`:  `False`\n",
      "*        `sample_name`:  `test`\n",
      "*              `scale`:  `False`\n",
      "*             `silent`:  `False`\n",
      "*   `single_or_paired`:  `single`\n",
      "*                `sob`:  `False`\n",
      "*           `testmode`:  `False`\n",
      "*            `trimmer`:  `seqtk`\n",
      "*          `umi_fastp`:  `False`\n",
      "*            `umi_len`:  `0`\n",
      "*          `verbosity`:  `None`\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Some assets are not found. You can update your REFGENIE config file or point directly to the file using the noted command-line arguments:\n",
      "  Assets not existing: refgene_tss (--TSS-name), ensembl_tss (--pi-tss), ensembl_gene_body (--pi-body), refgene_pre_mRNA (--pre-name), feat_annotation (--anno-name), refgene_exon (--exon-name), refgene_intron (--intron-name)\n",
      "Local input file: peppro_example/peppro/examples/data/test_r1.fq.gz\n",
      "\n",
      "> `File_mb`\t1.02\tPEPPRO\t_RES_\n",
      "\n",
      "> `Read_type`\tsingle\tPEPPRO\t_RES_\n",
      "\n",
      "> `Genome`\ths38d1\tPEPPRO\t_RES_\n",
      "Detected PRO input\n",
      "\n",
      "### Merge/link and fastq conversion:  (10-21 11:29:03) elapsed: 0.0 _TIME_\n",
      "\n",
      "Number of input file sets: 1\n",
      "Target to produce: `/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/raw/test.fastq.gz`  \n",
      "\n",
      "> `ln -sf /home/nsheff/code/bulker/docs_jupyter/peppro_example/peppro/examples/data/test_r1.fq.gz /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/raw/test.fastq.gz` (20905)\n",
      "<pre>\n",
      "</pre>\n",
      "Command completed. Elapsed time: 0:00:00. Running peak memory: 0.0GB.  \n",
      "  PID: 20905;\tCommand: ln;\tReturn code: 0;\tMemory used: 0.0GB\n",
      "\n",
      "Local input file: '/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/raw/test.fastq.gz'\n",
      "Found .fastq.gz file\n",
      "Target to produce: `/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/fastq/test_R1.fastq`  \n",
      "\n",
      "> `gzip -f -d -c /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/raw/test.fastq.gz > /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/fastq/test_R1.fastq` (20907)\n",
      "<pre>\n",
      "</pre>\n",
      "Command completed. Elapsed time: 0:00:00. Running peak memory: 0.002GB.  \n",
      "  PID: 20907;\tCommand: gzip;\tReturn code: 0;\tMemory used: 0.002GB\n",
      "\n",
      "\n",
      "> `Raw_reads`\t12500\tPEPPRO\t_RES_\n",
      "\n",
      "> `Fastq_reads`\t12500\tPEPPRO\t_RES_\n",
      "['/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/raw/test.fastq.gz']\n",
      "\n",
      "### FASTQ processing:  (10-21 11:29:03) elapsed: 0.0 _TIME_\n",
      "\n",
      "You set adapter arg to 'fastp' but you must select 'cutadapt' for single end data. Overriding.\n",
      "\n",
      "> `cutadapt --version`\n",
      "Target to produce: `/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/fastq/test_R1_processed.fastq`  \n",
      "\n",
      "> `( cutadapt -j 1 -m 18 -a TGGAATTCTCGGGTGCCAAGG /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/fastq/test_R1.fastq | seqtk trimfq -b 0 -L 30 - | seqtk seq -r - > /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/fastq/test_R1_processed.fastq ) 2> /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/cutadapt/test_cutadapt.txt` (20985)\n",
      "<pre>\n",
      "</pre>\n",
      "Command completed. Elapsed time: 0:00:01. Running peak memory: 0.057GB.  \n",
      "  PID: 20985;\tCommand: ;\tReturn code: 0;\tMemory used: 0.057GB\n",
      "\n",
      "Evaluating read trimming\n",
      "\n",
      "> `Trimmed_reads`\t11880\tPEPPRO\t_RES_\n",
      "\n",
      "> `Trim_loss_rate`\t4.96\tPEPPRO\t_RES_\n",
      "\n",
      "### Plot adapter insertion distribution (10-21 11:29:06) elapsed: 2.0 _TIME_\n",
      "\n",
      "Target to produce: `/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/cutadapt/test_adapter_insertion_distribution.pdf`  \n",
      "\n",
      "> `Rscript ./peppro_example/peppro/tools/PEPPRO.R cutadapt -i /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/cutadapt/test_cutadapt.txt -o /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/cutadapt` (21191)\n",
      "<pre>\n",
      "Error: Install the \"PEPPROr\" R package before proceeding.\n",
      "i.e. devtools::install_github(\"databio/peppro\", subdir=\"PEPPROr\")\n",
      "</pre>\n",
      "Command completed. Elapsed time: 0:00:01. Running peak memory: 0.057GB.  \n",
      "  PID: 21191;\tCommand: Rscript;\tReturn code: 0;\tMemory used: 0.019GB\n",
      "\n",
      "> `Adapter insertion distribution`\tcutadapt/test_adapter_insertion_distribution.pdf\tAdapter insertion distribution\tcutadapt/test_adapter_insertion_distribution.png\tPEPPRO\t_OBJ_\n",
      "\n",
      "### Prealignments (10-21 11:29:07) elapsed: 1.0 _TIME_\n",
      "\n",
      "You may use `--prealignments` to align to references before the genome alignment step. See docs.\n",
      "\n",
      "### Map to genome (10-21 11:29:07) elapsed: 0.0 _TIME_\n",
      "\n",
      "Target to produce: `/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_sort.bam`  \n",
      "\n",
      "> `bowtie2 -p 1 --very-sensitive -X 2000 --rg-id test -x /home/nsheff/code/bulker/docs_jupyter/peppro_example/hs38d1/bowtie2_index/default/hs38d1 -U /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/fastq/test_R1_processed.fastq | samtools view -bS - -@ 1  | samtools sort - -@ 1 -T /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/tmpjLFtWP -o /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_temp.bam` (21283,21287,21313)\n",
      "<pre>\n",
      "11880 reads; of these:\n",
      "  11880 (100.00%) were unpaired; of these:\n",
      "    10476 (88.18%) aligned 0 times\n",
      "    372 (3.13%) aligned exactly 1 time\n",
      "    1032 (8.69%) aligned >1 times\n",
      "11.82% overall alignment rate\n",
      "</pre>\n",
      "Command completed. Elapsed time: 0:00:02. Running peak memory: 0.057GB.  \n",
      "  PID: 21287;\tCommand: samtools;\tReturn code: 0;\tMemory used: 0.018GB  \n",
      "  PID: 21283;\tCommand: bowtie2;\tReturn code: 0;\tMemory used: 0.018GB  \n",
      "  PID: 21313;\tCommand: samtools;\tReturn code: 0;\tMemory used: 0.018GB\n",
      "\n",
      "\n",
      "> `samtools view -q 10 -b -@ 1 -U /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_fail_qc.bam /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_temp.bam > /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_sort.bam` (21527)\n",
      "<pre>\n",
      "</pre>\n",
      "Command completed. Elapsed time: 0:00:01. Running peak memory: 0.057GB.  \n",
      "  PID: 21527;\tCommand: samtools;\tReturn code: 0;\tMemory used: 0.018GB\n",
      "\n",
      "\n",
      "> `samtools depth /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_sort.bam | awk '{counter++;sum+=$3}END{print sum/counter}'`\n",
      "\n",
      "> `Mapped_reads`\t1404\tPEPPRO\t_RES_\n",
      "\n",
      "> `QC_filtered_reads`\t989.0\tPEPPRO\t_RES_\n",
      "\n",
      "> `Aligned_reads`\t415\tPEPPRO\t_RES_\n",
      "\n",
      "> `Alignment_rate`\t3.49\tPEPPRO\t_RES_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> `Total_efficiency`\t3.32\tPEPPRO\t_RES_\n",
      "\n",
      "> `Read_depth`\t1.26\tPEPPRO\t_RES_\n",
      "\n",
      "### Compress all unmapped read files (10-21 11:29:11) elapsed: 4.0 _TIME_\n",
      "\n",
      "Target to produce: `/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_temp.bam.bai`  \n",
      "\n",
      "> `samtools index /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_temp.bam` (21800)\n",
      "<pre>\n",
      "</pre>\n",
      "Command completed. Elapsed time: 0:00:01. Running peak memory: 0.057GB.  \n",
      "  PID: 21800;\tCommand: samtools;\tReturn code: 0;\tMemory used: 0.019GB\n",
      "\n",
      "\n",
      "> `samtools idxstats /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_temp.bam | grep -we 'chrM' -we 'chrMT' -we 'M' -we 'MT' -we 'rCRSd' -we 'rCRSd_3k'| cut -f 3`\n",
      "\n",
      "> `samtools stats /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_sort.bam | grep '^SN' | cut -f 2- | grep 'maximum length:' | cut -f 2-`\n",
      "\n",
      "### Calculate NRF, PBC1, and PBC2 (10-21 11:29:13) elapsed: 2.0 _TIME_\n",
      "\n",
      "Target to produce: `/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_sort.bam.bai`  \n",
      "\n",
      "> `samtools index /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_sort.bam` (22028)\n",
      "<pre>\n",
      "</pre>\n",
      "Command completed. Elapsed time: 0:00:01. Running peak memory: 0.057GB.  \n",
      "  PID: 22028;\tCommand: samtools;\tReturn code: 0;\tMemory used: 0.019GB\n",
      "\n",
      "Target to produce: `/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/QC_hs38d1/test_bamQC.tsv`  \n",
      "\n",
      "> `./peppro_example/peppro/tools/bamQC.py --silent -i /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_sort.bam -c 1 -o /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/QC_hs38d1/test_bamQC.tsv --silent` (22096)\n",
      "<pre>\n",
      "</pre>\n",
      "Command completed. Elapsed time: 0:00:03. Running peak memory: 0.068GB.  \n",
      "  PID: 22096;\tCommand: ./peppro_example/peppro/tools/bamQC.py;\tReturn code: 0;\tMemory used: 0.068GB\n",
      "\n",
      "\n",
      "> `awk '{ for (i=1; i<=NF; ++i) { if ($i ~ \"NRF\") c=i } getline; print $c }' /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/QC_hs38d1/test_bamQC.tsv`\n",
      "\n",
      "> `awk '{ for (i=1; i<=NF; ++i) { if ($i ~ \"PBC1\") c=i } getline; print $c }' /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/QC_hs38d1/test_bamQC.tsv`\n",
      "\n",
      "> `awk '{ for (i=1; i<=NF; ++i) { if ($i ~ \"PBC2\") c=i } getline; print $c }' /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/QC_hs38d1/test_bamQC.tsv`\n",
      "\n",
      "> `NRF`\t0.89\tPEPPRO\t_RES_\n",
      "\n",
      "> `PBC1`\t0.95\tPEPPRO\t_RES_\n",
      "\n",
      "> `PBC2`\t30.75\tPEPPRO\t_RES_\n",
      "Target to produce: `/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_unmap.bam`  \n",
      "\n",
      "> `samtools view -b -@ 1 -f 4  /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_temp.bam > /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_unmap.bam` (22108)\n",
      "<pre>\n",
      "</pre>\n",
      "Command completed. Elapsed time: 0:00:01. Running peak memory: 0.068GB.  \n",
      "  PID: 22108;\tCommand: samtools;\tReturn code: 0;\tMemory used: 0.019GB\n",
      "\n",
      "\n",
      "> `samtools view -c -f 4 -@ 1 /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_temp.bam`\n",
      "\n",
      "> `Unmapped_reads`\t10476.0\tPEPPRO\t_RES_\n",
      "\n",
      "### Split BAM by strand (10-21 11:29:18) elapsed: 5.0 _TIME_\n",
      "\n",
      "Target to produce: `/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_plus.bam`,`/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_minus.bam`  \n",
      "\n",
      "> `samtools view -bh -F 20 /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_sort.bam > /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_plus.bam` (22257)\n",
      "<pre>\n",
      "</pre>\n",
      "Command completed. Elapsed time: 0:00:01. Running peak memory: 0.068GB.  \n",
      "  PID: 22257;\tCommand: samtools;\tReturn code: 0;\tMemory used: 0.019GB\n",
      "\n",
      "\n",
      "> `samtools view -bh -f 16 /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_sort.bam > /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_minus.bam` (22322)\n",
      "<pre>\n",
      "</pre>\n",
      "Command completed. Elapsed time: 0:00:01. Running peak memory: 0.068GB.  \n",
      "  PID: 22322;\tCommand: samtools;\tReturn code: 0;\tMemory used: 0.019GB\n",
      "\n",
      "Skipping TSS -- TSS enrichment requires TSS annotation file: refgene_tss\n",
      "Target to produce: `/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/QC_hs38d1/chr_order.txt`  \n",
      "\n",
      "> `samtools view -H /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_sort.bam | grep 'SN:' | awk -F':' '{print $2,$3}' | awk -F' ' -v OFS='\t' '{print $1,$3}' > /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/QC_hs38d1/chr_order.txt` (22386,22391,22395,22403)\n",
      "<pre>\n",
      "</pre>\n",
      "Command completed. Elapsed time: 0:00:01. Running peak memory: 0.068GB.  \n",
      "  PID: 22386;\tCommand: samtools;\tReturn code: 0;\tMemory used: 0.018GB  \n",
      "  PID: 22395;\tCommand: awk;\tReturn code: 0;\tMemory used: 0.004GB  \n",
      "  PID: 22391;\tCommand: grep;\tReturn code: 0;\tMemory used: 0.001GB  \n",
      "  PID: 22403;\tCommand: awk;\tReturn code: 0;\tMemory used: 0.004GB\n",
      "\n",
      "Target to produce: `/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/QC_hs38d1/chr_keep.txt`  \n",
      "\n",
      "> `cut -f 1 /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/QC_hs38d1/chr_order.txt > /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/QC_hs38d1/chr_keep.txt` (22455)\n",
      "<pre>\n",
      "</pre>\n",
      "Command completed. Elapsed time: 0:00:00. Running peak memory: 0.068GB.  \n",
      "  PID: 22455;\tCommand: cut;\tReturn code: 0;\tMemory used: 0.0GB\n",
      "\n",
      "Skipping PI -- Pause index requires 'TSS' and 'gene body' annotation files: ensembl_tss and ensembl_gene_body\n",
      "Skipping FRiP -- Fraction of reads in pre-mRNA requires pre-mRNA annotation file: refgene_pre_mRNA\n",
      "\n",
      "### Calculate fraction of reads in features (FRiF) (10-21 11:29:20) elapsed: 2.0 _TIME_\n",
      "\n",
      "\n",
      "### Plot FRiF (10-21 11:29:20) elapsed: 0.0 _TIME_\n",
      "\n",
      "\n",
      "> `samtools view -@ 1 -q 10 -c -F4 /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_plus.bam`\n",
      "\n",
      "> `samtools view -@ 1 -q 10 -c -F4 /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_minus.bam`\n",
      "\n",
      "### Produce bigWig files (10-21 11:29:21) elapsed: 1.0 _TIME_\n",
      "\n",
      "Target to produce: `/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/signal_hs38d1/test_plus_body_0-mer.bw`  \n",
      "\n",
      "> `samtools index /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_plus.bam` (22609)\n",
      "<pre>\n",
      "</pre>\n",
      "Command completed. Elapsed time: 0:00:01. Running peak memory: 0.068GB.  \n",
      "  PID: 22609;\tCommand: samtools;\tReturn code: 0;\tMemory used: 0.02GB\n",
      "\n",
      "\n",
      "> `./peppro_example/peppro/tools/bamSitesToWig.py -i /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_plus.bam -c /home/nsheff/code/bulker/docs_jupyter/peppro_example/hs38d1/fasta/default/hs38d1.chrom.sizes -o /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/signal_hs38d1/test_plus_body_0-mer.bw -p 1 --variable-step --tail-edge` (22674)\n",
      "<pre>\n",
      "Registering input file: '/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_plus.bam'\n",
      "Temporary files will be stored in: 'tmp_test_plus_cuttrace_qU7o0L'\n",
      "Processing with 1 cores...\n",
      "stdin is empty of data\n",
      "Reduce step (merge files)...\n",
      "Merging 121 files into output file: '/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/signal_hs38d1/test_plus_body_0-mer.bw'\n",
      "Couldn't open tmp_test_plus_cuttrace_qU7o0L/JTFH01000350.1.txt.bw\n",
      "</pre>\n",
      "Command completed. Elapsed time: 0:01:19. Running peak memory: 0.068GB.  \n",
      "  PID: 22674;\tCommand: ./peppro_example/peppro/tools/bamSitesToWig.py;\tReturn code: 0;\tMemory used: 0.057GB\n",
      "\n",
      "Target to produce: `/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/signal_hs38d1/test_minus_body_0-mer.bw`  \n",
      "\n",
      "> `samtools index /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_minus.bam` (31803)\n",
      "<pre>\n",
      "</pre>\n",
      "Command completed. Elapsed time: 0:00:01. Running peak memory: 0.068GB.  \n",
      "  PID: 31803;\tCommand: samtools;\tReturn code: 0;\tMemory used: 0.019GB\n",
      "\n",
      "\n",
      "> `./peppro_example/peppro/tools/bamSitesToWig.py -i /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_minus.bam -c /home/nsheff/code/bulker/docs_jupyter/peppro_example/hs38d1/fasta/default/hs38d1.chrom.sizes -o /home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/signal_hs38d1/test_minus_body_0-mer.bw -p 1 --variable-step --tail-edge` (31872)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pre>\n",
      "Registering input file: '/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/aligned_hs38d1/test_minus.bam'\n",
      "Temporary files will be stored in: 'tmp_test_minus_cuttrace_ljeMBw'\n",
      "Processing with 1 cores...\n",
      "Reduce step (merge files)...\n",
      "Merging 124 files into output file: '/home/nsheff/code/bulker/docs_jupyter/peppro_example/output/test/signal_hs38d1/test_minus_body_0-mer.bw'\n",
      "</pre>\n",
      "Command completed. Elapsed time: 0:01:23. Running peak memory: 0.068GB.  \n",
      "  PID: 31872;\tCommand: ./peppro_example/peppro/tools/bamSitesToWig.py;\tReturn code: 0;\tMemory used: 0.057GB\n",
      "\n",
      "Starting cleanup: 5 files; 4 conditional files for cleanup\n",
      "\n",
      "Cleaning up flagged intermediate files. . .\n",
      "\n",
      "Cleaning up conditional list. . .\n",
      "\n",
      "### Pipeline completed. Epilogue\n",
      "*        Elapsed time (this run):  0:03:01\n",
      "*  Total elapsed time (all runs):  0:02:59\n",
      "*         Peak memory (this run):  0.0675 GB\n",
      "*        Pipeline completed time: 2019-10-21 11:32:04\n"
     ]
    }
   ],
   "source": [
    "./peppro_example/peppro/pipelines/peppro.py \\\n",
    "  --sample-name test \\\n",
    "  --genome hs38d1 \\\n",
    "  --input peppro_example/peppro/examples/data/test_r1.fq.gz \\\n",
    "  --single-or-paired single \\\n",
    "  -O peppro_example/output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline has now completed successfully and we can explore the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mpeppro_example/output/\u001b[00m\n",
      "└── \u001b[01;34mtest\u001b[00m\n",
      "    ├── \u001b[01;34maligned_hs38d1\u001b[00m\n",
      "    │   ├── test_fail_qc.bam\n",
      "    │   ├── test_minus.bam\n",
      "    │   ├── test_minus.bam.bai\n",
      "    │   ├── test_plus.bam\n",
      "    │   ├── test_plus.bam.bai\n",
      "    │   ├── test_sort.bam\n",
      "    │   ├── test_sort.bam.bai\n",
      "    │   └── test_unmap.bam\n",
      "    ├── \u001b[01;34mcutadapt\u001b[00m\n",
      "    │   └── test_cutadapt.txt\n",
      "    ├── \u001b[01;34mfastq\u001b[00m\n",
      "    ├── \u001b[01;34mfastqc\u001b[00m\n",
      "    ├── objects.tsv\n",
      "    ├── \u001b[01;32mPEPPRO_cleanup.sh\u001b[00m\n",
      "    ├── PEPPRO_commands.sh\n",
      "    ├── PEPPRO_completed.flag\n",
      "    ├── PEPPRO_log.md\n",
      "    ├── PEPPRO_profile.tsv\n",
      "    ├── \u001b[01;34mQC_hs38d1\u001b[00m\n",
      "    │   └── test_bamQC.tsv\n",
      "    ├── \u001b[01;34mraw\u001b[00m\n",
      "    │   └── \u001b[01;36mtest.fastq.gz\u001b[00m -> \u001b[01;31m/home/nsheff/code/bulker/docs_jupyter/peppro_example/peppro/examples/data/test_r1.fq.gz\u001b[00m\n",
      "    ├── \u001b[01;34msignal_hs38d1\u001b[00m\n",
      "    │   └── test_minus_body_0-mer.bw\n",
      "    └── stats.tsv\n",
      "\n",
      "8 directories, 19 files\n"
     ]
    }
   ],
   "source": [
    "tree peppro_example/output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've successfully run a complete pipeline without having to install any of the software that runs the commands in the workflow. We're also able to interactively explore the environment that ran the workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "That's basically it. If you're a workflow developer, all you need to do is [write your own manifest](manifest.md) and distribute it with your workflow; in 3 lines of code, users will be able to run your workflow using modular containers, using the container engine of their choice.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
